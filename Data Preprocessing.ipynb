{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c4adb9e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string, re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20280ddf",
   "metadata": {},
   "source": [
    "### Clean Data\n",
    "**clean_input** is function that take the *string(text)*, remove **links** and **Punctuation** from it,<br> convert it to **lower case** and maintains **arabic and english** letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d1433253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   text_to_clean = re.sub(r'[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', text_to_fuck)\n",
    "def clean_input(text_to_clean):\n",
    "    text_to_clean = text_to_clean.lower()\n",
    "    text_to_clean = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', text_to_clean)\n",
    "    text_to_clean = re.sub(r'[0-9]+', '', text_to_clean)\n",
    "    text_to_clean = re.sub(r'[^a-zA-Z\\u0621-\\u064A\\s]', '', text_to_clean)\n",
    "    text_to_clean = re.sub(r'numbernumber+', 'number', text_to_clean)\n",
    "    return text_to_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c7fa30",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "**pandas.read_csv** function : load Data from *excel* files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "02626103",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Dataset/train.csv')\n",
    "test = pd.read_csv('Dataset/test.csv')\n",
    "y_test = pd.read_csv('Dataset/submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc283ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Shape : {train.shape}\")\n",
    "print(f\"Test Shape : {test.shape}\")\n",
    "print(f\"Submit Shape : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef245e8e",
   "metadata": {},
   "source": [
    "### Show Raw Data\n",
    "Data before clean it and merge **title** and **text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6ad92eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1c90b01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1  20801  Russian warships ready to strike terrorists ne...   \n",
       "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4  20804                    Keiser Report: Meme Wars (E995)   \n",
       "\n",
       "                    author                                               text  \n",
       "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...  \n",
       "1                      NaN  Russian warships ready to strike terrorists ne...  \n",
       "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...  \n",
       "3            Daniel Victor  If at first you don’t succeed, try a different...  \n",
       "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "000ecf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : (20800, 5)\n",
      "Test Shape : (5200, 4)\n",
      "Submit Shape : (5200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Shape : {train.shape}\")\n",
    "print(f\"Test Shape : {test.shape}\")\n",
    "print(f\"Submit Shape : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a6d9c",
   "metadata": {},
   "source": [
    "### Check Null Value in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8d6bf9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "75f7e423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title     122\n",
       "author    503\n",
       "text        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1a92ffe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object    3\n",
       "int64     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()\n",
    "test.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27948229",
   "metadata": {},
   "source": [
    "### Fill Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "aba7dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_data(data):\n",
    "    data[\"title\"] = data[\"title\"].fillna(\"No Title\")\n",
    "    data[\"text\"] = data[\"text\"].fillna(\"No text\")\n",
    "    return data\n",
    "\n",
    "train = fill_data(train)\n",
    "test = fill_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "52211b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title        0\n",
       "author    1957\n",
       "text         0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "44ce9c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title       0\n",
       "author    503\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72056a6b",
   "metadata": {},
   "source": [
    "### Merge & Drop\n",
    "merge **title** and **text** sections </br> drop **author** and **id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e8ff97ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800,)\n",
      "(20800, 1)\n"
     ]
    }
   ],
   "source": [
    "#Initializ y_train and x_train\n",
    "train['text_merge'] = train['title'].astype(str) + \" \" + train['text'].astype(str)\n",
    "x_train = train['text_merge']\n",
    "y_train = train.drop(['id','title','author','text','text_merge'], axis = 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e7c5cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializ y_test and x_test\n",
    "test['text_merge'] = test['title'].astype(str) + \" \" + test['text'].astype(str)\n",
    "x_test = test['text_merge']\n",
    "y_test = y_test.drop(['id'], axis = 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "401899d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5200,)\n",
      "(5200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f9de2",
   "metadata": {},
   "source": [
    "### Delete Stop Words\n",
    "Delete **Arabic&English** stop words and **punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c67574db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "punc = list(string.punctuation)\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words_2 = stopwords.words(\"arabic\")\n",
    "\n",
    "\n",
    "def processing_text(data):\n",
    "    data.lower()\n",
    "\n",
    "    data = \" \".join([word for word in word_tokenize(data)\n",
    "                        if ((word not in stop_words) and (word not in stop_words_2) and (word not in punc))])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b8fe6",
   "metadata": {},
   "source": [
    "### Use Clean Data Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "538606a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x_train.shape[0]):\n",
    "    x_train.values[i] = clean_input(x_train[i])\n",
    "    x_train.values[i] = processing_text(x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "af490535-5fdf-4284-bb6c-a7a9b682cf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    house dem aide we didnt even see comeys letter...\n",
       "1    flynn hillary clinton big woman on campus  bre...\n",
       "2    why the truth might get you fired why the trut...\n",
       "3     civilians killed in single us airstrike have ...\n",
       "4    iranian woman jailed for fictional unpublished...\n",
       "Name: text_merge, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7308da5",
   "metadata": {},
   "source": [
    "### Tokenizer Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b26b7138",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_words = 1000\n",
    "maxlen = 4000\n",
    "truncat = 'post'\n",
    "padd = 'post'\n",
    "token = '<OOV>'\n",
    "\n",
    "tokenizer = Tokenizer(oov_token = token)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "X_train = pad_sequences(sequences_train, maxlen = maxlen, truncating = truncat, padding = padd)\n",
    "\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "X_test = pad_sequences(sequences_test, maxlen = maxlen, truncating = truncat, padding = padd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b54bc8",
   "metadata": {},
   "source": [
    "### Normalize Data\n",
    "Scale the tokenized data between **0** and **1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_float = X_train.astype('float32')\n",
    "X_test_float = X_test.astype('float32')\n",
    "\n",
    "max_val = np.max([np.max(X_train_float), np.max(X_test_float)])\n",
    "min_val = np.min([np.min(X_train_float), np.min(X_test_float)])\n",
    "\n",
    "X_train_normalized = (X_train_float - min_val) / (max_val - min_val)\n",
    "X_test_normalized = (X_test_float - min_val) / (max_val - min_val)\n",
    "\n",
    "X_train_normalized = np.clip(X_train_normalized, 0, 1)\n",
    "X_test_normalized = np.clip(X_test_normalized, 0, 1)\n",
    "\n",
    "print(X_train_normalized.shape)\n",
    "print(X_test_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6bbf035b-b182-44db-a8dd-f9355c702748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 4000)\n",
      "(5200, 4000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
